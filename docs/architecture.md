# Architecture

## Overview

Switch creates a chat-based interface for AI coding assistants. Each conversation session becomes a separate XMPP contact, allowing you to manage multiple concurrent AI conversations from any XMPP client (Conversations, Gajim, Dino, etc.).

The codebase lives at `~/switch`. AI agents working on this project should reference `~/switch/AGENTS.md` for conventions and `~/switch/memory/` for persistent context.

<!-- DIAGRAM:system -->
<!-- (auto-generated by scripts/sync-diagrams.py; edit docs/diagrams/system.mermaid) -->
```mermaid
flowchart LR
    subgraph User["User Devices"]
        Client["XMPP Client<br/>(Conversations, Gajim, etc.)"]
    end

    subgraph Tailnet["Tailscale Network"]
        subgraph DevBox["Development Machine"]
            XMPP["ejabberd<br/>(XMPP Server)"]

            subgraph Orchestrators["Orchestrator Contacts"]
                direction TB
                CC["cc@...<br/>(Claude Code)"]
                OC["oc@...<br/>(OpenCode GLM 4.7)"]
                OCGPT["oc-gpt@...<br/>(OpenCode GPT 5.2)"]
            end

            Sessions["Session Bots<br/>(task-name@...)"]

            subgraph Engines["AI CLIs"]
                direction TB
                OpenCode["OpenCode CLI"]
                Claude["Claude CLI"]
            end
        end
    end

    Client <-->|"Tailscale IP"| XMPP
    XMPP <--> CC
    XMPP <--> OC
    XMPP <--> OCGPT
    XMPP <--> Sessions
    Sessions --> OpenCode
    Sessions --> Claude

    classDef orchestrator fill:#f5f5e8,stroke:#8a7d60,color:#2c2c2c;
    class CC,OC,OCGPT orchestrator;
```
<!-- /DIAGRAM:system -->

<!-- DIAGRAM:system-detailed -->
<!-- (auto-generated by scripts/sync-diagrams.py; edit docs/diagrams/system-detailed.mermaid) -->
```mermaid
flowchart TB
  %% Switch detailed architecture + message flow

  %% =====================
  %% XMPP edge
  %% =====================
  User["User XMPP Client"]
  XMPP["ejabberd (XMPP)"]

  User <--> XMPP

  %% =====================
  %% Orchestration plane
  %% =====================
  Dispatcher["DispatcherBot\nsrc/bots/dispatcher.py"]
  Manager["SessionManager\nsrc/manager.py"]
  Lifecycle["lifecycle/sessions.py\nsrc/lifecycle/sessions.py"]

  DB["sessions.db (SQLite)\nrepos: src/db.py\n- SessionRepository\n- MessageRepository\n- RalphLoopRepository"]

  XMPP -->|"message to orchestrator JID"| Dispatcher
  Dispatcher -->|create/kill| Manager
  Manager --> Lifecycle
  Lifecycle -->|create/close rows| DB

  %% =====================
  %% Per-session bot
  %% =====================
  SessionBot["SessionBot\nsrc/bots/session/bot.py"]
  Inbound["Inbound parsing\nsrc/bots/session/inbound.py"]
  Typing["TypingIndicator\nsrc/bots/session/typing.py"]
  Actor["[Q] SessionActor (queue + serialize)\nsrc/bots/session/actor.py"]

  XMPP -->|"message to session JID"| SessionBot
  SessionBot --> Inbound
  SessionBot --> Typing
  SessionBot --> Actor
  SessionBot -->|"persist chat"| DB

  %% =====================
  %% Attachments
  %% =====================
  AttStore["AttachmentStore\nsrc/attachments/store.py"]
  AttServer["Attachments HTTP server\nsrc/attachments/server.py"]

  SessionBot -->|"download image URLs"| AttStore
  AttStore -->|"build public_url"| AttServer

  %% =====================
  %% Runners boundary
  %% =====================
  Registry["runners registry\nsrc/runners/registry.py\ncreate_runner(engine, ...)" ]
  Ports["Runner port\nsrc/runners/ports.py\nrun() -> events\ncancel()" ]

  Actor -->|dequeue 1 at a time| Registry
  Registry --> Ports

  %% =====================
  %% Claude runner path (local)
  %% =====================
  ClaudeRunner["ClaudeRunner\nsrc/runners/claude/runner.py\n(SubprocessTransport -> claude CLI)"]
  LocalTools["Local tools\n(bash/read/write/edit/glob/grep/webfetch)"]

  Ports -->|engine=claude| ClaudeRunner
  ClaudeRunner -->|tool invocations| LocalTools
  ClaudeRunner -->|events: tool/text/result| SessionBot

  %% =====================
  %% OpenCode runner path (server)
  %% =====================
  OpenCodeRunner["OpenCodeRunner\nsrc/runners/opencode/runner.py"]
  OpenCodeConfig["OpenCodeConfig\nsrc/runners/opencode/config.py"]
  OpenCodeClient["OpenCodeClient\nsrc/runners/opencode/client.py"]
  OpenCodeTransport["OpenCodeTransport\nsrc/runners/opencode/transport.py"]
  OpenCodeProcessor["OpenCodeEventProcessor\nsrc/runners/opencode/processor.py"]
  Pipeline["iter_queue_pipeline()\nsrc/runners/pipeline.py\n(session gating + idle timeout)"]
  OpenCodeServer["External OpenCode server\n(HTTP + SSE; executes tools)"]

  Ports -->|engine=opencode| OpenCodeRunner
  OpenCodeRunner --> OpenCodeConfig
  OpenCodeRunner --> OpenCodeClient
  OpenCodeRunner --> OpenCodeTransport
  OpenCodeRunner --> OpenCodeProcessor
  OpenCodeRunner --> Pipeline
  OpenCodeClient <==>|"HTTP + SSE"| OpenCodeServer
  OpenCodeRunner -->|events: tool/text/question/result| SessionBot

  %% =====================
  %% Questions (OpenCode -> user -> OpenCode)
  %% =====================
  Question["Question meta\n(ask user; wait for reply)"]

  OpenCodeRunner -->|"event: question"| Question
  Question -->|"XMPP meta"| XMPP
  XMPP -->|"question-reply meta"| SessionBot
  SessionBot -->|"answer_question/reject"| OpenCodeClient

  %% =====================
  %% Cancellation paths
  %% =====================
  Cancel["[X] cancel_operations()\n(SessionBot)"]

  SessionBot -.-> Cancel
  Cancel -.->|"drop queued"| Actor
  Cancel -.->|"Runner.cancel()"| Ports
  Ports -.->|"/abort"| OpenCodeTransport

  classDef cancel stroke:#b00020,stroke-width:2px,fill:#fff5f6,color:#111;
  class Cancel,Actor cancel;
```
<!-- /DIAGRAM:system-detailed -->

To keep this diagram consistent across docs, update `docs/diagrams/system.mermaid` and run:

```bash
python3 scripts/sync-diagrams.py
```

## Network Topology

Switch runs entirely within a **Tailscale network** (tailnet):

- **XMPP Server (ejabberd)**: Runs on the dev machine, listens on its Tailscale IP
- **User's XMPP Client**: Connects via Tailscale - no port forwarding or public exposure needed
- **All bots**: Connect locally to ejabberd on the same machine

This means:
- You need ejabberd installed and configured on the dev machine
- Your XMPP client connects to the machine's Tailscale IP (e.g., `100.x.x.x`)
- Everything stays private within your tailnet

## Components

### Orchestrator Contacts

Multiple orchestrators, each tied to a specific AI engine:

| Contact | Engine | Model |
|---------|--------|-------|
| `cc@domain` | Claude Code | Opus |
| `oc@domain` | OpenCode | GLM 4.7 |
| `oc-gpt@domain` | OpenCode | GPT 5.2 |
| `oc-glm-zen@domain` | OpenCode | GLM 4.7 (Zen) |
| `oc-gpt-or@domain` | OpenCode | GPT 5.2 (OpenRouter) |
| `oc-kimi-coding@domain` | OpenCode | Kimi K2.5 (Kimi for Coding) |

Send any message to an orchestrator to create a new session using that engine. Each orchestrator handles:

- Session creation with auto-generated names from message content
- Global commands (`/list`, `/kill`, `/recent`, `/help`)

### Session Bots (`session-name@domain`)

One bot per conversation. Each session:

- Has its own XMPP account (created dynamically via ejabberdctl)
- Maintains conversation context with the AI backend
- Can switch between OpenCode and Claude engines
- Tracks costs, tokens, and tool usage

### Session Manager

Coordinates all bots:

- Starts/stops session bots
- Restores active sessions on restart
- Manages XMPP account lifecycle

### Lifecycle (Source of Truth)

Session create/kill semantics are centralized in:

- `src/lifecycle/sessions.py`

Dispatcher bots, session bots, and shell scripts should delegate to this module
to avoid drift.

## Data Flow

1. **New Session**: Message to orchestrator (cc/oc/oc-gpt) → slugify name → create XMPP account → spawn SessionBot with engine config → process first message

2. **Continuing Session**: Message to session contact → SessionBot receives → run AI backend → stream response back

3. **Session Output**: All AI output logged to `~/switch/output/<session>.log` for debugging and `/peek` command

## Database Schema

SQLite database (`~/switch/sessions.db`) stores:

```sql
sessions (
    name TEXT PRIMARY KEY,        -- e.g., "fix-auth-bug"
    xmpp_jid TEXT,                -- e.g., "fix-auth-bug@domain"
    xmpp_password TEXT,
    claude_session_id TEXT,       -- For resuming Claude conversations
    opencode_session_id TEXT,     -- For resuming OpenCode conversations
    active_engine TEXT,           -- "opencode" or "claude"
    model_id TEXT,                -- OpenCode model selection
    status TEXT                   -- "active" or "closed"
)
```

## AI Backends

### OpenCode

- Runs `opencode run --format json`
- Parses streaming JSON events
- Supports model selection and reasoning modes
- Tracks detailed token usage

### Claude Code

- Runs `claude -p --output-format stream-json`
- Parses streaming JSON events
- Uses Opus model
- Supports session resumption

## Ralph Loop

Autonomous iteration system for long-running tasks:

```
/ralph 20 Fix all type errors --wait 5
```

Runs the AI in a loop until:
- Max iterations reached
- Completion promise detected in output
- Manual cancellation via `/ralph-cancel`
- Wait interval between iterations (default ~0.03 min, configurable with `--wait`)
